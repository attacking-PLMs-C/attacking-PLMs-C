import pandas as pd
import warnings
import os
import json
from scipy.stats import entropy
import torch
import torch.nn.functional as F
import numpy as np
from sklearn import metrics
import operator
import re
import pickle as pkl
import tqdm
from importlib import import_module
import sys
import argparse
from transformers import RobertaTokenizer
from torch.nn import DataParallel
from dataset_iter1 import DatasetIterdtor
sys.path.append('.')

os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore')
# os.environ['CUDA_VISIBLE_DEVICES'] = '3'

def get_feature_vector(fcode, tokenizer):
    fcode = re.sub(r'(\s)+', ' ', fcode).strip()
    ftokens = ''.join(fcode.split(' '))
    ftokens = tokenizer.tokenize(ftokens)[:510]
    ftokens = [tokenizer.cls_token] + ftokens + [tokenizer.sep_token]
    fids = tokenizer.convert_tokens_to_ids(ftokens)
    padding_length = 512 - len(fids)
    fids += [tokenizer.pad_token_id] * padding_length
    return fids

def get_prediction(f_code, tokenizer, model, config):
    f_ids = get_feature_vector(f_code, tokenizer)
    f_ids = torch.tensor(f_ids).to(config.device)
    out, _, _ = model(f_ids)
    predict = torch.max(out.data, 1)[1].item()
    return predict

def greedy_attack(config, args, model, db, file_to_label):
    model.eval()
    angle_testcases = 0.0
    atten_testcases = 0.0
    comp_testcases = 0.0
    angle_adv_cases = 0.0
    atten_adv_cases = 0.0
    comp_adv_cases = 0.0
    tokenizer = RobertaTokenizer.from_pretrained("microsoft/codebert-base")
    bar = tqdm.tqdm(total=len(db))
    with torch.no_grad():
        for _, item in db.iterrows():
            fid = item.id
            label = int(file_to_label[fid])
            features = item.features
            more_candidates = item.more_candidates
            angle_candidates = sorted(features, key=operator.itemgetter(1), reverse=True)
            atten_candidates = sorted(features, key=operator.itemgetter(2), reverse=True)
            # print(candidates)
            tag1 = False
            for ac in angle_candidates:
            # angle_candidate = angle_candidates[0]
                angle_code = open(ac[0], 'r').read().strip()
                fname = ac[0].split('/')[-1]
                an_predict = get_prediction(angle_code, tokenizer, model, config)
                if label != an_predict and tag1 == False:
                    tag1 = True
                    angle_adv_cases += 1
                    angle_testcases += 1
                    if more_candidates != []:
                        for mc in more_candidates:
                            mc_name = mc[0].split('/')[0]
                            if mc_name == fname:
                                mc_code = open(mc[0], 'r').read().strip()
                                mc_prediction = get_prediction(mc_code, tokenizer, model, config)
                                if mc_prediction != label:
                                    angle_adv_cases += 1
                                    angle_testcases += 1
                if tag1 == True:
                    break
            if tag1 == False:
                angle_testcases += 1

            tag2 = False
            for atc in atten_candidates:
                atten_code = open(atc[0], 'r').read().strip()
                fname = atc[0].split('/')[-1]
                at_predict = get_prediction(atten_code, tokenizer, model, config)
                if label != at_predict and tag2 == False:
                    tag2 = True
                    atten_adv_cases += 1
                    atten_testcases += 1
                    if more_candidates != []:
                        for mc in more_candidates:
                            mc_name = mc[0].split('/')[0]
                            if mc_name == fname:
                                mc_code = open(mc[0], 'r').read().strip()
                                mc_prediction = get_prediction(mc_code, tokenizer, model, config)
                                if mc_prediction != label:
                                    atten_adv_cases += 1
                                    atten_testcases += 1
                if tag2 == True:
                    break
            if tag2 == False:
                atten_testcases += 1
            bar.update()
    bar.close()
    print(angle_adv_cases, angle_testcases)
    print(atten_adv_cases, atten_testcases)
    an_acc = angle_adv_cases / angle_testcases
    at_acc = atten_adv_cases / atten_testcases
    # comp_acc = comp_adv_cases / all_testcases
    # test_acc = metrics.accuracy_score(total_labels, total_predicts)
    # test_precision = metrics.precision_score(total_labels, total_predicts)
    # test_recall = metrics.recall_score(total_labels, total_predicts)
    # test_f1 = metrics.f1_score(total_labels, total_predicts)
    # test_report = metrics.classification_report(total_labels, total_predicts, target_names=label_list, digits=4)
    # test_confusion = metrics.confusion_matrix(total_labels, total_predicts)
    # test_loss = total_losses / len(test_iter)

    msg = 'An_Acc: {0:>6.2%}, At_Acc: {1:>6.2%}'
    print(msg.format(an_acc, at_acc))
    # print("Precision, Recall and F1-Score...")
    # print(test_report)
    # print("Confusion Matrix...")
    # print(test_confusion)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    # parser.add_argument('--train_data', type=str, default='./data/train_set_token.pkl', help='input train dataset')
    # parser.add_argument('--test_data', type=str)
    parser.add_argument('--model', type=str, default='Encoder', help='model name')
    # parser.add_argument('--layer', type=int, default=12)
    parser.add_argument('--trans', type=str, default='code_rename')
    parser.add_argument('--level', type=str, default='surface')
    args = parser.parse_args()

    model_name = args.model
    X = import_module('module.' + model_name)
    config = X.Config()
    device = config.device
    dir_name = './save_dict/'
    config.save_path = dir_name + 'CodeBERT_12_5.ckpt'

    # test_dataset = pkl.load(open(args.test_data, 'rb'))
    # test_iter = DatasetIterdtor(test_dataset, config.batch_size, device)
    model = X.Encoder(config)
    model = model.to(device)
    model.load_state_dict(torch.load(config.save_path))

    file_to_label = {}
    with open('code_labels.txt', 'r') as fp:
        all_lines = fp.read().strip().split('\n')
        for line in tqdm.tqdm(all_lines):
            fname = line.split('  ')[0]
            label  = line.split('  ')[-1]
            file_to_label[fname] = label

    s_path = './' + args.trans + '/' + args.level + '_naturalness_selection.pkl'
    db = pd.read_pickle(s_path)
    # print(db)
    greedy_attack(config, args, model, db, file_to_label)
    # msg = 'Test acc: {0:>6.2%}, Test precision: {1:>6.2%}, Test recall: {2:>6.2%}, Test f1: {3:>6.2%}'
    # print(msg.format(acc, p, r, f1))
    # print("Precision, Recall and F1-Score...")
    # print(test_report)
    # print("Confusion Matrix...")
    # print(test_confusion)